import duckdb
import streamlit as st
import pandas as pd
import os
from pathlib import Path
from typing import Any, Dict, Generator, List, Optional, Tuple
from openai import OpenAI

@st.cache_resource
def get_duck() -> duckdb.DuckDBPyConnection:
    """Return a shared DuckDB connection persisted on disk."""
    return duckdb.connect("cache.duckdb")


@st.cache_data(ttl=600, show_spinner=False)
def refresh_cache() -> bool:
    """Pull data from Snowflake and materialize into DuckDB tables."""
    con = get_duck()
    sf = st.connection("snowflake")
    project_df = sf.query("SELECT * FROM FINAL_PROJECT;", ttl=300)
    invoice_df = sf.query("SELECT * FROM FINAL_INVOICE;", ttl=300)
    meta_df = sf.query("SELECT * FROM COLUMN_META;", ttl=300)

    con.register("project_df", project_df)
    con.execute("CREATE OR REPLACE TABLE project AS SELECT * FROM project_df")

    con.register("invoice_df", invoice_df)
    con.execute("CREATE OR REPLACE TABLE invoice AS SELECT * FROM invoice_df")

    if meta_df is not None and not meta_df.empty:
        con.register("meta_df", meta_df)
        con.execute("CREATE OR REPLACE TABLE column_meta AS SELECT * FROM meta_df")
    return True


@st.cache_data(ttl=120, show_spinner=False)
def load_cached_data() -> tuple[pd.DataFrame, pd.DataFrame]:
    """Load Project/Invoice data from DuckDB cache."""
    con = get_duck()
    try:
        project = con.execute("SELECT * FROM project").df()
    except Exception:
        project = pd.DataFrame()
    try:
        invoice = con.execute("SELECT * FROM invoice").df()
    except Exception:
        invoice = pd.DataFrame()
    return project, invoice


@st.cache_data(ttl=600, show_spinner=False)
def load_cached_meta() -> pd.DataFrame:
    """Load column metadata from DuckDB cache."""
    con = get_duck()
    try:
        return con.execute("SELECT * FROM column_meta").df()
    except Exception:
        return pd.DataFrame(columns=["Table_name", "Field_name", "Description"])


@st.cache_data(ttl=1800, show_spinner=False)
def load_cached_pmbok() -> pd.DataFrame:
    """Load PMBOK chunks from DuckDB cache (if any)."""
    con = get_duck()
    try:
        return con.execute("SELECT * FROM pmbok_chunks ORDER BY chunk_index").df()
    except Exception:
        return pd.DataFrame(columns=["chunk_index", "text"])


@st.cache_data(ttl=1800, show_spinner=False)
def load_cached_pmbok_vectors() -> pd.DataFrame:
    """Load PMBOK vector embeddings from DuckDB cache (if any)."""
    con = get_duck()
    try:
        return con.execute("SELECT * FROM pmbok_vectors ORDER BY chunk_index").df()
    except Exception:
        return pd.DataFrame(columns=["chunk_index", "text", "embedding"])


def load_env_key(key: str, env_path: Path = Path(".env")) -> Optional[str]:
    if key in os.environ:
        return os.environ[key]
    if not env_path.exists():
        return None
    for line in env_path.read_text().splitlines():
        if not line or line.strip().startswith("#") or "=" not in line:
            continue
        k, v = line.split("=", 1)
        if k.strip() == key:
            return v.strip().strip('"').strip("'")
    return None


def _get_openrouter_api_key() -> Optional[str]:
    """Return OpenRouter API key from secrets or environment."""
    try:
        return st.secrets.get("api", {}).get("OPENROUTER_API_KEY")
    except Exception:
        return load_env_key("OPENROUTER_API_KEY")


def ai_chart_summary(title: str, df: pd.DataFrame, hint: str, key: str, meta_text: str = "", model: str = "openai/gpt-oss-20b:free") -> None:
    """
    Render a button to summarize a chart via OpenRouter GPT-OSS 20B.
    Shows output in a collapsible expander.
    """
    state_key = f"ai_summary_{key}"
    if st.button(f"ü§ñ AI summarize: {title}", key=key, use_container_width=True):
        api_key = _get_openrouter_api_key()
        if not api_key:
            st.error("OpenRouter client is not available. Set OPENROUTER_API_KEY in environment/.env.")
            return
        data_preview = "No data"
        if df is not None and not df.empty:
            data_preview = df.head(50).to_csv(index=False)
        system_prompt = (
            "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô "
            "‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏£‡∏≤‡∏ü‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô bullet 2-4 ‡∏Ç‡πâ‡∏≠ ‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏° ‡∏à‡∏∏‡∏î‡∏™‡∏π‡∏á/‡∏ï‡πà‡∏≥ ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ "
            "‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏û‡∏≠‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡∏£‡∏á‡πÑ‡∏õ‡∏ï‡∏£‡∏á‡∏°‡∏≤"
        )
        if meta_text:
            system_prompt += f"\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• schema/‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå:\n{meta_text}"
        user_prompt = (
            f"‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Å‡∏£‡∏≤‡∏ü: {title}\n"
            f"‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏£‡∏≤‡∏ü: {hint}\n"
            f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (CSV ‡πÅ‡∏ñ‡∏ß‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á):\n{data_preview}\n"
            "‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏£‡∏≤‡∏ü‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô bullet ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"
        )
        try:
            client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=api_key)
            resp = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
            )
            st.session_state[state_key] = resp.choices[0].message.content
        except Exception as exc:  # noqa: BLE001
            st.error(f"AI summary failed: {exc}")
    if state_key in st.session_state:
        with st.expander("‡∏î‡∏π‡∏™‡∏£‡∏∏‡∏õ AI", expanded=False):
            st.info(st.session_state[state_key])
